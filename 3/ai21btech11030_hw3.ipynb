{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "XrJUvmrGKr_K"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "def derv_sigmoid(x):\n",
        "  return x*(1-x)\n",
        "\n",
        "def MSE(y_t, y_p):\n",
        "  return 0.5*np.mean((y_t - y_p)**2)"
      ],
      "metadata": {
        "id": "GsbFvu6IK-yI"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ANN:\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "\n",
        "    self.W_ih = np.random.randn(input_size, hidden_size)\n",
        "    self.b_h = np.zeros((1, hidden_size))\n",
        "    self.W_ho = np.random.randn(hidden_size, output_size)\n",
        "    self.b_o = np.zeros((1, output_size))\n",
        "\n",
        "  def forward(self, X):\n",
        "    self.z1 = np.dot(X, self.W_ih) + self.b_h\n",
        "    self.a1 = sigmoid(self.z1)\n",
        "    self.z2 = np.dot(self.a1, self.W_ho) + self.b_o\n",
        "    self.a2 = sigmoid(self.z2)\n",
        "    return self.a2\n",
        "\n",
        "  def backward(self, X, y, lr):\n",
        "    error = self.a2 - y\n",
        "    delta_o = error*derv_sigmoid(self.a2)\n",
        "    error_h = delta_o.dot(self.W_ho.T)\n",
        "    delta_h = error_h*derv_sigmoid(self.a1)\n",
        "\n",
        "    self.W_ho += self.a1.T.dot(delta_o) * lr\n",
        "    self.b_o += np.sum(delta_o, axis=0, keepdims=True) * lr\n",
        "    self.W_ih += X.T.dot(delta_h) * lr\n",
        "    self.b_h += np.sum(delta_h, axis=0, keepdims=True) * lr\n",
        "\n",
        "  def train(self, X_train, y_train, X_test, y_test, num_epochs, lr, batch_size):\n",
        "    training_loss = []\n",
        "    testing_loss = []\n",
        "    training_accuracy = []\n",
        "    testing_accuracy = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      np.random.seed(0)\n",
        "      np.random.shuffle(X_train)\n",
        "      np.random.shuffle(y_train)\n",
        "\n",
        "      for i in range(0, len(X_train), batch_size):\n",
        "        mini_X = X_train[i:i + batch_size]\n",
        "        mini_y = y_train[i:i + batch_size]\n",
        "\n",
        "        self.forward(mini_X)\n",
        "        self.backward(mini_X, mini_y, lr)\n",
        "\n",
        "      train_loss = MSE(y_train, self.output)\n",
        "      train_accuracy = np.mean(np.round(self.output) == y_train)\n",
        "      training_loss.append(train_loss)\n",
        "      training_accuracy.append(train_accuracy)\n",
        "\n",
        "      test_output = self.forward(X_test)\n",
        "\n",
        "      test_loss = MSE(y_test, test_output)\n",
        "      test_accuracy = np.mean(np.round(test_output) == y_test)\n",
        "      testing_loss.append(test_loss)\n",
        "      testing_accuracy.append(test_accuracy)"
      ],
      "metadata": {
        "id": "coE53XOPiCzg"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "data_sizes = [100, 200, 500]\n",
        "\n",
        "for data_size in data_sizes:\n",
        "\n",
        "  input = np.random.randint(0, 2, size=(data_size, 2))\n",
        "\n",
        "  noise = np.random.normal(0, 0.1, input.shape)\n",
        "\n",
        "  X = np.clip(input + noise, 0, 1)\n",
        "\n",
        "  labels_xor = np.logical_xor(X[:, 0], X[:, 1]).astype(int)\n",
        "  labels_and = np.logical_and(X[:, 0], X[:, 1]).astype(int)\n",
        "  labels_or = np.logical_or(X[:, 0], X[:, 1]).astype(int)\n",
        "\n",
        "  X_train, X_test = X[:80], X[80:]\n",
        "  y_train_xor, y_test_xor = labels_xor[:80], labels_xor[80:]\n",
        "  y_train_and, y_test_and = labels_and[:80], labels_and[80:]\n",
        "  y_train_or, y_test_or = labels_or[:80], labels_or[80:]\n",
        "\n",
        "  input_size = 2\n",
        "  hidden_size = 2\n",
        "  output_size = 1\n",
        "\n",
        "  lr = 0.01\n",
        "  num_epochs = 100\n",
        "  batch_size = 32\n",
        "\n",
        "  nn_xor = ANN(input_size, hidden_size, output_size)\n",
        "  train_loss_xor, test_loss_xor, train_accuracy_xor, test_accuracy_xor = nn_xor.train(X_train, y_train_xor, X_test, y_test_xor, num_epochs, lr, batch_size)\n",
        "\n",
        "  nn_and = ANN(input_size, hidden_size, output_size)\n",
        "  train_loss_and, test_loss_and, train_accuracy_and, test_accuracy_and = nn_and.train(X_train, y_train_and, X_test, y_test_and, num_epochs, lr, batch_size)\n",
        "\n",
        "  nn_or = ANN(input_size, hidden_size, output_size)\n",
        "  train_loss_or, test_loss_or, train_accuracy_or, test_accuracy_or = nn_or.train(X_train, y_train_or, X_test, y_test_or, num_epochs, lr, batch_size)\n",
        "\n",
        "  plt.figure(figsize=(12, 6))\n",
        "  plt.plot(train_loss_xor, label=\"Train Loss (XOR)\")\n",
        "  plt.plot(test_loss_xor, label=\"Test Loss (XOR)\")\n",
        "  plt.title(\"XOR Training and Testing Loss\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "\n",
        "  plt.subplot(1, 3, 2)\n",
        "  plt.plot(train_loss_and, label=\"Train Loss (AND)\")\n",
        "  plt.plot(test_loss_and, label=\"Test Loss (AND)\")\n",
        "  plt.title(\"AND Training and Testing Loss\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "\n",
        "  plt.subplot(1, 3, 3)\n",
        "  plt.plot(train_loss_or, label=\"Train Loss (OR)\")\n",
        "  plt.plot(test_loss_or, label=\"Test Loss (OR)\")\n",
        "  plt.title(\"OR Training and Testing Loss\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure(figsize=(12, 6))\n",
        "  plt.subplot(1, 3, 1)\n",
        "  plt.plot(train_accuracy_xor, label=\"Train Accuracy (XOR)\")\n",
        "  plt.plot(test_accuracy_xor, label=\"Test Accuracy (XOR)\")\n",
        "  plt.title(\"XOR Training and Testing Accuracy\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "\n",
        "  plt.subplot(1, 3, 2)\n",
        "  plt.plot(train_accuracy_and, label=\"Train Accuracy (AND)\")\n",
        "  plt.plot(test_accuracy_and, label=\"Test Accuracy (AND)\")\n",
        "  plt.title(\"AND Training and Testing Accuracy\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "\n",
        "  plt.subplot(1, 3, 3)\n",
        "  plt.plot(train_accuracy_or, label=\"Train Accuracy (OR)\")\n",
        "  plt.plot(test_accuracy_or, label=\"Test Accuracy (OR)\")\n",
        "  plt.title(\"OR Training and Testing Accuracy\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "prt4vVlXpZP8",
        "outputId": "7b1193ec-d069-47a5-f31f-77093b817921"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-7ff37400bff7>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0mnn_xor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mANN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m   train_loss_xor, test_loss_xor, train_accuracy_xor, test_accuracy_xor = nn_xor.train(\n\u001b[0m\u001b[1;32m     31\u001b[0m       X_train, y_train_xor, X_test, y_test_xor, num_epochs, lr)\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-151d3947446e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_train, y_train, X_test, y_test, num_epochs, lr)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m       \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-151d3947446e>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, X, y, lr)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mdelta_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mderv_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0merror_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta_o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_ho\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mdelta_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_h\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mderv_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (80,80) and (1,2) not aligned: 80 (dim 1) != 1 (dim 0)"
          ]
        }
      ]
    }
  ]
}